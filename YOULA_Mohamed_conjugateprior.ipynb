{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOULA_Mohamed conjugateprior.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thOZW78Y6z_L"
      },
      "source": [
        "IMPORTATION DES PACKAGES "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8uEKHUh62PD"
      },
      "source": [
        "import numpy as np\r\n",
        "from scipy.stats import chi2\r\n",
        "import scipy.stats as stats\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgPlSEYK6ChD"
      },
      "source": [
        "GENERONS UN ECHANTILLON D'OBSERVATIONS SUIVANT UNE DISTRIBUTION GAUSSIENNE  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQdWeHyx6DQG",
        "outputId": "12bd8297-70e0-468c-b116-82c7caec23a1"
      },
      "source": [
        "mu, sigma = 2, 0.1 # Moyenne égale à 2 et variance égale à 0.1  # dans la suite nous considérons que ces  paramètres sont inconu\r\n",
        "                   # et que nous devons les estimer suivant l'inférence bayesienne  \r\n",
        "n=10 # taille de l'échantion gaussien\r\n",
        "s = np.random.normal(mu, sigma, n)\r\n",
        "s # nos dix observations \r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.06094653, 1.87057334, 1.9972149 , 2.04857346, 1.98754009,\n",
              "       2.1486869 , 2.24165026, 1.94891517, 2.14331911, 1.87257894])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp3LjjTU6Q2H"
      },
      "source": [
        "1) Estimation de la moyenne en fixant la variance 0.1   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2ZqROVg6RGP",
        "outputId": "7fc5fb1d-a469-4d0f-f29f-52d92fea36fe"
      },
      "source": [
        "mu0, sigma0  =0, 1  # parametres de la distribution gaussienne corespondant au priore de la moyenne \r\n",
        "\r\n",
        "mu_post=((sigma0)*(sigma)/(sigma + n*sigma0))*( (mu0/sigma0) + (sum(s)/sigma)) # estimation de la moyenne du posterior  \r\n",
        "\r\n",
        "sigma_post=((1/sigma0) + (n/sigma**2))**(-1) # estimation de la variance du posterior\r\n",
        "\r\n",
        "mu_hat_dist = np.random.normal(mu_post, sigma_post, n)  \r\n",
        "mu_hat_dist # distribution gaussienne du posteriore "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.01280394, 2.01449563, 2.01189735, 2.01223019, 2.01037769,\n",
              "       2.01164122, 2.01302099, 2.01138446, 2.01147165, 2.01104248])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CyVDc-Z6fmx"
      },
      "source": [
        "On constate bien que les valeurs retournée ci-dessus sont proche de la vraie moyenne (2) de notre distribution initiale  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG76ImMv-g-_"
      },
      "source": [
        "2) Estimation de la variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PQrWj5S6mF1",
        "outputId": "1fe5c70b-53be-45f4-8823-921f53cff5fd"
      },
      "source": [
        "# Ici nous générons un échantillon  suivant une distribussion chi2 en faissant la somme des carrés de n+v vaiable gaussien de moyenne 0   \r\n",
        "# et de variance p2 qui la secode expression du Posterior hyperparameters donnée dans le tablaeu pour Scaled inverse chi-squared\r\n",
        "\r\n",
        "v=1 # dégé de liberté de notre chi2 vaudra v+n, comme indiqué dans le tableau  \r\n",
        "vec=[(i-mu)**2 for i in s] \r\n",
        "p2=((v*sigma0 + sum(vec))/(v+n))\r\n",
        "norm = stats.norm(0,p2)\r\n",
        "\r\n",
        "x1=np.zeros(n)\r\n",
        "for i in range(v+n):.\r\n",
        "    x1 = x1 + norm.rvs(size=n)**2\r\n",
        "f=x1\r\n",
        "f"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02108697, 0.08076059, 0.03505886, 0.0801638 , 0.09889136,\n",
              "       0.13173401, 0.07515498, 0.06881223, 0.0872443 , 0.04296646])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2in0RvGyB6vn"
      },
      "source": [
        "On obtient des valeurs qui sont presque toutes proches de la vraie variance\r\n",
        "(0.1) de notre distribution initiale     "
      ]
    }
  ]
}